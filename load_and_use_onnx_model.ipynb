{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7610511a",
   "metadata": {},
   "source": [
    "### import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e83eab6",
   "metadata": {
    "id": "4e83eab6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "import numpy as np\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a29f397",
   "metadata": {},
   "source": [
    "### create Function that load and build the lookup mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a79ca287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_StringLookup():\n",
    "    '''\n",
    "        this function load the characters from vocabulary txt file \n",
    "        then build the lookup mapper again \n",
    "        and return the mapper\n",
    "    '''\n",
    "    # Load the vocabulary from the saved file\n",
    "    with open('vocabulary.txt', 'r', encoding='utf-8') as vocab_file:\n",
    "        vocabulary = vocab_file.read().split('\\n')\n",
    "\n",
    "    # Create a new StringLookup layer with the loaded vocabulary and configuration\n",
    "    char_to_num = tf.keras.layers.StringLookup(\n",
    "        vocabulary=vocabulary,\n",
    "        mask_token=None,  # You may need to adjust this depending on your configuration\n",
    "    )\n",
    "    \n",
    "    # Mapping integers back to original characters.\n",
    "    num_to_char = StringLookup(\n",
    "        vocabulary= vocabulary, mask_token=None, invert=True\n",
    "    )\n",
    "    return char_to_num, num_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2b6bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num, num_to_char = load_StringLookup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3434f1f",
   "metadata": {},
   "source": [
    "### create the image processing Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15fd1ac7",
   "metadata": {
    "id": "15fd1ac7"
   },
   "outputs": [],
   "source": [
    "def segment_the_line(thresh):\n",
    "    '''\n",
    "        this function (vertically only) finds \n",
    "        where the text starts and end in the image\n",
    "        and return the index of stating and ending\n",
    "    '''\n",
    "    thresh = thresh//255.0\n",
    "    up_j = 99999999\n",
    "    down_j= -999999999\n",
    "    for j,  i in enumerate( thresh):\n",
    "        if i.min() == 0:\n",
    "            if(up_j> j): \n",
    "                up_j = j\n",
    "\n",
    "            if(down_j< j): \n",
    "                down_j = j\n",
    "    \n",
    "    return max(up_j-3,0), min(down_j+4, len(thresh))\n",
    "\n",
    "def segmentTheLine(thresh):\n",
    "    '''\n",
    "        this function take a black and white image, \n",
    "        then crop the text from the white background\n",
    "    \n",
    "    '''\n",
    "    i, j = segment_the_line(thresh)\n",
    "    thresh = thresh[i:j]\n",
    "    thresh = cv2.rotate(thresh, cv2.ROTATE_90_CLOCKWISE)\n",
    "    i, j = segment_the_line(thresh)\n",
    "    thresh = thresh[i:j]\n",
    "    thresh = cv2.rotate(thresh, cv2.ROTATE_90_CLOCKWISE)\n",
    "    thresh = cv2.rotate(thresh, cv2.ROTATE_90_CLOCKWISE)\n",
    "    thresh = cv2.rotate(thresh, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "    return thresh\n",
    "\n",
    "def process_nationalID_address(image):\n",
    "    '''\n",
    "        this function applys image processing methods as: \n",
    "        - thersholding:  to convert the image to black and white\n",
    "        - enhancement: using smoothing then Sharpening\n",
    "        - the line segmentaion function \n",
    "        then return the results\n",
    "    '''\n",
    "    \n",
    "    image = cv2.resize(image, (10000, 1000))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding\n",
    "    _, thresh = cv2.threshold(gray, 85, 255, cv2.THRESH_BINARY)\n",
    "    _, thresh = cv2.threshold(thresh, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # apply image enhancement\n",
    "    smoothed_image = cv2.GaussianBlur(thresh, (7, 7), 0)\n",
    "    kernel = np.array([[-1,-1,-1], [-1, 9,-1],[-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(smoothed_image, -1, kernel) # applying the sharpening kernel to the input image & displaying it.\n",
    "\n",
    "    # Perform morphological operations to clean up the image\n",
    "    kernel = np.ones((9, 3), np.uint8)\n",
    "    img_erosion = cv2.erode(sharpened, kernel, iterations=2)\n",
    "\n",
    "    result = cv2.resize(img_erosion, (1000, 100))\n",
    "    result = segmentTheLine(result)\n",
    "    _, result = cv2.threshold(result, 0, 255, cv2.THRESH_BINARY)\n",
    "    return result\n",
    "\n",
    "def preprocess_image(image_paths, width, hight):\n",
    "    '''\n",
    "        this function load the images from the paths, \n",
    "        then preprocess them \n",
    "        then returns a numpy array of images\n",
    "    '''\n",
    "    images = []\n",
    "    for path in tqdm(image_paths):\n",
    "        # Load and preprocess your images here (e.g., resizing and normalizing)\n",
    "        image = cv2.imread(path)  # Load the image using OpenCV\n",
    "        image = process_nationalID_address(image)\n",
    "        image = cv2.resize(image, (width, hight))\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#         _, image = cv2.threshold(image, 250, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        image = image // 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "        images.append(image)\n",
    "    # Next we need to reshape our data for the convolutional network\n",
    "    images=np.array(images)\n",
    "    images = images.reshape(images.shape[0], hight, width,1)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd2c14",
   "metadata": {},
   "source": [
    "### Create function that decode the model output and map it to final predicted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nDH6DOu8HOFN",
   "metadata": {
    "id": "nDH6DOu8HOFN"
   },
   "outputs": [],
   "source": [
    "max_len=68\n",
    "def decode_batch_predictions(pred):\n",
    "    '''\n",
    "    this function decode the output of the model \n",
    "    and map the charcters\n",
    "    then returns the whole text\n",
    "    '''\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search.\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "        :, :max_len\n",
    "    ]\n",
    "    # Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa16da7",
   "metadata": {},
   "source": [
    "### load the ONNX model then use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9331989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the prediction model\n",
    "ort_session = ort.InferenceSession(\"./models/my_prediction_model_final.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e823e509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('image', 'dense3')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provide input data as a dictionary\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs()[0].name\n",
    "input_name , output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31f0d422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# load the image\n",
    "image_path = './OCR_Text_Dataset/OCR_Text/1.jpg'\n",
    "text_path = './OCR_Text_Dataset/OCR_Text/1.txt'\n",
    "\n",
    "image = preprocess_image([image_path], 300, 20)\n",
    "label_file = open(text_path, \"r\",  encoding=\"utf8\")\n",
    "actual_text = label_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "869bdb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual text:  1641 شارع أم الرخم متفرع من زحوم في ١٢٥٨ أردناستانغ\n",
      "predicted text:  103 شارع أم الرمم متفرع من رموم في ١٠١١ أرالستان\n"
     ]
    }
   ],
   "source": [
    "# path the input to the model and print the predicted text\n",
    "\n",
    "input_data = np.array(image, dtype=np.float32)  \n",
    "\n",
    "result = ort_session.run([output_name], {input_name: input_data})\n",
    "\n",
    "predicted_text = decode_batch_predictions(np.array(result[0]))[0]\n",
    "\n",
    "print(\"actual text: \", actual_text) \n",
    "print(\"predicted text: \", predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45022046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ff075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
